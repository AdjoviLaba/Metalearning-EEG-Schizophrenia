{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "T5nbpw6RooyW"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "\n",
        "# To improve the speed of setting up, retrieve only the files for the two groups used in training\n",
        "# Swap with the line below to get the entire dataset as a zip file\n",
        "# gdown.download('https://drive.google.com/uc?id=1-QTtycxsVNeym17zrMBSZCAAtEZEs05p', '/content/miniimagenet.zip', quiet=False)\n",
        "\n",
        "\n",
        "# Use the correct file ID from the Google Drive link\n",
        "file_id = '18cAvtcJc4jMkLi_QgA7vsN1oe2z026Dp'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'miniimagenet.zip', quiet=False)\n",
        "\n",
        "# After downloading, check if the file exists\n",
        "import os\n",
        "if os.path.exists('miniimagenet.zip'):\n",
        "    print(\"File downloaded successfully.\")\n",
        "else:\n",
        "    print(\"File download failed.\")\n",
        "\n",
        "images_directory = '/content/miniimagenet/images/'\n",
        "if not os.path.exists(images_directory):\n",
        "  os.makedirs(images_directory)\n",
        "!unzip -qq /content/miniimagenet.zip -d {images_directory}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN2dnz7ritjJ",
        "outputId": "9dc99dc2-5c43-4b91-ad37-ca864423a100"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18cAvtcJc4jMkLi_QgA7vsN1oe2z026Dp\n",
            "From (redirected): https://drive.google.com/uc?id=18cAvtcJc4jMkLi_QgA7vsN1oe2z026Dp&confirm=t&uuid=a6c680ea-e582-4fcd-b30c-785aadbf89ac\n",
            "To: /content/miniimagenet.zip\n",
            "100%|██████████| 6.74G/6.74G [00:36<00:00, 183MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully.\n",
            "replace /content/miniimagenet/images/n01532829/n01532829_10006.JPEG? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# get the CSV with the list of all file names\n",
        "mini_imagenet_file_list_csv = '/content/all_imagenet_file_names.csv'\n",
        "\n",
        "\n",
        "# Download the CSV file from Google Drive using the file ID\n",
        "file_id = '112iJze_LpZrGZbtR6XohaycpMRGCXLel'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', mini_imagenet_file_list_csv, quiet=False)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_list = pd.read_csv(mini_imagenet_file_list_csv,  on_bad_lines='skip')\n",
        "print(file_list.head())\n",
        "\n",
        "selected_groups = ['n01532829', 'n01558993']\n",
        "samples_miniimagenet = file_list[file_list['label'].isin(selected_groups)].groupby('label').first()\n",
        "\n",
        "\n",
        "# Other options for group pairs\n",
        "# n01532829, n01558993\n",
        "# n02108551, n02108915"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IlR8VhnkHWZ",
        "outputId": "0f72006c-05ce-4a04-f255-e3d1ae16ea52"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=112iJze_LpZrGZbtR6XohaycpMRGCXLel\n",
            "To: /content/all_imagenet_file_names.csv\n",
            "100%|██████████| 1.82M/1.82M [00:00<00:00, 46.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              file_name      label\n",
            "0  n07697537_49047.JPEG  n07697537\n",
            "1  n07697537_33979.JPEG  n07697537\n",
            "2  n07697537_10215.JPEG  n07697537\n",
            "3  n07697537_15450.JPEG  n07697537\n",
            "4   n07697537_5990.JPEG  n07697537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGPtV09KSzPI"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "For this analysis, the first two groups above are used n01532829 and n01558993. These are two similar-looking bird species. The goal is to train the classifier to detect minor details that distinguish the two groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "726kH5bGLQau",
        "outputId": "fc84bdad-c21f-4f93-8ff9-cceb74d23940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['file_name'], dtype='object')\n",
            "Sample for group ID  n01532829\n",
            "/content/miniimagenet/images/ n01532829_930.JPEG\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/miniimagenet/images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-4288365d2b4b>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#plt.close('all')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mimgplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0;34m\"``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m             )\n\u001b[0;32m-> 1563\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1565\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3431\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3432\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/miniimagenet/images'"
          ]
        }
      ],
      "source": [
        "# show a sample from the two selected classes\n",
        "\n",
        "from PIL import Image\n",
        "from importlib import reload\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "print(samples_miniimagenet.columns)\n",
        "\n",
        "for image_path in samples_miniimagenet['filename'].unique():\n",
        "    print('Sample for group ID ', image_path[:9])\n",
        "    print(images_directory, image_path )\n",
        "    reload(plt)\n",
        "\n",
        "    img=mpimg.imread(images_directory, image_path)\n",
        "    #plt.close('all')\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lW6hGHlVUd2a"
      },
      "outputs": [],
      "source": [
        "# Since the imagenet files are all in the same directory, they can be used as-is\n",
        "# with the maml-pytorch setup and do not need to be processed further at this point.\n",
        "# However, the directory does need to be added to the Python training file\n",
        "\n",
        "file_list[file_list['label'].isin(selected_groups)].to_csv(images_directory + '/train.csv')\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMEsTbSjKGXF",
        "outputId": "28ed1386-5c43-4a77-ca76-0cd7ba0269cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1WZ1yIFE2bng0McnY_4UBJHqTttsXTTNX\n",
            "From (redirected): https://drive.google.com/uc?id=1WZ1yIFE2bng0McnY_4UBJHqTttsXTTNX&confirm=t&uuid=618b5645-37d7-4f93-9eca-4af61ac35690\n",
            "To: /content/eeg_sz_spectrograms.zip\n",
            "100%|██████████| 44.2M/44.2M [00:00<00:00, 48.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Get the EEG spectrograms zip file and unzip it\n",
        "eeg_image_directory = '/content/eeg_sz_spectrograms'\n",
        "gdown.download('https://drive.google.com/uc?id=1WZ1yIFE2bng0McnY_4UBJHqTttsXTTNX', '{}.zip'.format(eeg_image_directory), quiet=False)\n",
        "!unzip -qq {eeg_image_directory}.zip -d {eeg_image_directory}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3jU4_ON9NLFJ"
      },
      "outputs": [],
      "source": [
        "# rename\n",
        "dl_link = '/content/eeg_sz_spectrograms/gen_data_20s_70pct_overlap_-_high_nfft_all_channels_sml/'\n",
        "!mv \"{dl_link}/hc\" {eeg_image_directory}\n",
        "!mv \"{dl_link}/sz\" {eeg_image_directory}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkZkXEI-USMt",
        "outputId": "fa09d1df-7b3e-486c-d2d8-9f51b5a1a413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Subjects assigned to groups using sklearn.model_selection.train_test_split\n",
            "Test group:  hc2, hc3, hc4, hc12, hc1, hc6, sz2, sz3, sz4, sz9, sz1, sz6 \n",
            "\n",
            "Validation group:  hc0, hc7, hc13, hc11, hc8, hc5, sz0, sz7, sz13, sz8, sz5 \n",
            "\n",
            "      filename label\n",
            "0  hc11_48.png    hc\n",
            "1  hc11_13.png    hc\n",
            "2  hc11_12.png    hc\n",
            "3  hc11_22.png    hc\n",
            "4  hc11_73.png    hc\n"
          ]
        }
      ],
      "source": [
        "# Use EEG of Sz for validation and testing\n",
        "# Extract files from an eeg_sz spectrogram directory where files are saved by subject\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "rand_seed = 1\n",
        "# List of raw patient file IDs that should be skipped based on categorization as outliers\n",
        "ignore_list = ['h09', 'h10', 's10', 's11', 's12']\n",
        "hc_subject_ids = ['hc' + str(i) for i in range(14) if \"h{:02}\".format(i) not in ignore_list]\n",
        "sz_subject_ids = ['sz' + str(i) for i in range(14) if \"s{:02}\".format(i) not in ignore_list]\n",
        "all_subject_ids = np.concatenate([hc_subject_ids, sz_subject_ids], axis=0)\n",
        "validate_hc, test_hc = train_test_split(hc_subject_ids, test_size=0.5, random_state=rand_seed)\n",
        "validate_sz, test_sz = train_test_split(sz_subject_ids, test_size=0.5, random_state=rand_seed)\n",
        "\n",
        "validation_ids = np.concatenate([validate_hc, validate_sz])\n",
        "test_ids = np.concatenate([test_hc, test_sz])\n",
        "\n",
        "\n",
        "print('\\nSubjects assigned to groups using sklearn.model_selection.train_test_split')\n",
        "print('Test group: ', \", \".join(test_ids), \"\\n\")\n",
        "print('Validation group: ', \", \".join(validation_ids), \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "test_images_output_directory = 'all_test_images'\n",
        "validation_images_output_directory = 'all_validation_images'\n",
        "\n",
        "if not os.path.exists(test_images_output_directory):\n",
        "    os.mkdir(test_images_output_directory)\n",
        "if not os.path.exists(validation_images_output_directory):\n",
        "    os.mkdir(validation_images_output_directory)\n",
        "\n",
        "\n",
        "\n",
        "# Note: CSV is only used for MAML and Prototypical networks\n",
        "def gen_csv_and_copy_sz_files(image_dir, img_output_dir, participant_ids, output_name, split_with_csv=False):\n",
        "    subdir_data = []\n",
        "    for group in ['hc', 'sz']: #['Healthy_Control', 'Sz_Patient']:\n",
        "        for pid in os.listdir(image_dir + '/' + group): # by participant IDs\n",
        "            if pid in participant_ids:\n",
        "              for file in os.listdir(image_dir + '/' + group + '/' + pid):\n",
        "                file_data = {'filename': file, 'label': group}\n",
        "                subdir_data.append(file_data)\n",
        "                destination = img_output_dir + '/' + file if split_with_csv else  '{}/{}/{}'.format(img_output_dir, group, file)\n",
        "                if not os.path.exists('{}/{}'.format(img_output_dir, group)):\n",
        "                  os.makedirs('{}/{}'.format(img_output_dir, group))\n",
        "                copyfile(image_dir + '/' + group + '/' + pid + '/' + file,  destination )\n",
        "    if split_with_csv:\n",
        "      pd.DataFrame(subdir_data).to_csv(img_output_dir + '/' + output_name)\n",
        "    return pd.DataFrame(subdir_data)\n",
        "\n",
        "\n",
        "df = gen_csv_and_copy_sz_files(image_dir=eeg_image_directory,\n",
        "                                img_output_dir=test_images_output_directory,\n",
        "                                participant_ids=test_ids,\n",
        "                               split_with_csv=True,\n",
        "                                output_name= 'test.csv')\n",
        "df = gen_csv_and_copy_sz_files(image_dir=eeg_image_directory,\n",
        "                                img_output_dir=validation_images_output_directory,\n",
        "                                participant_ids=validation_ids,\n",
        "                               split_with_csv=True,\n",
        "                                output_name= 'test.csv') #file must be name test.csv\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iuCAgmsQxc6",
        "outputId": "576a101e-5649-4064-b0b1-1d68755a15cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'maml_pytorch'...\n",
            "remote: Enumerating objects: 226, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 226 (delta 8), reused 7 (delta 3), pack-reused 209 (from 1)\u001b[K\n",
            "Receiving objects: 100% (226/226), 672.94 KiB | 2.35 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ],
      "source": [
        "# Get the project files from github\n",
        "!git clone https://github.com/MTynes/MAML-Pytorch.git maml_pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKft9PEXeKVl",
        "outputId": "f58eb321-49e7-4972-bfcd-c00ee759212a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/maml_pytorch/learner.py:29: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if name is 'conv2d':\n",
            "/content/maml_pytorch/learner.py:38: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'convt2d':\n",
            "/content/maml_pytorch/learner.py:47: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'linear':\n",
            "/content/maml_pytorch/learner.py:56: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'bn':\n",
            "/content/maml_pytorch/learner.py:84: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if name is 'conv2d':\n",
            "/content/maml_pytorch/learner.py:89: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'convt2d':\n",
            "/content/maml_pytorch/learner.py:94: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'linear':\n",
            "/content/maml_pytorch/learner.py:98: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'leakyrelu':\n",
            "/content/maml_pytorch/learner.py:103: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'avg_pool2d':\n",
            "/content/maml_pytorch/learner.py:106: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'max_pool2d':\n",
            "/content/maml_pytorch/learner.py:138: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if name is 'conv2d':\n",
            "/content/maml_pytorch/learner.py:144: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'convt2d':\n",
            "/content/maml_pytorch/learner.py:150: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'linear':\n",
            "/content/maml_pytorch/learner.py:155: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'bn':\n",
            "/content/maml_pytorch/learner.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'flatten':\n",
            "/content/maml_pytorch/learner.py:165: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'reshape':\n",
            "/content/maml_pytorch/learner.py:168: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'relu':\n",
            "/content/maml_pytorch/learner.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'leakyrelu':\n",
            "/content/maml_pytorch/learner.py:172: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'tanh':\n",
            "/content/maml_pytorch/learner.py:174: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'sigmoid':\n",
            "/content/maml_pytorch/learner.py:176: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'upsample':\n",
            "/content/maml_pytorch/learner.py:178: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'max_pool2d':\n",
            "/content/maml_pytorch/learner.py:180: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif name is 'avg_pool2d':\n",
            "usage: train_custom_dataset.py [-h] [--train_dir TRAIN_DIR]\n",
            "                               [--further_training_dir FURTHER_TRAINING_DIR]\n",
            "                               [--validation_dir VALIDATION_DIR] [--test_dir TEST_DIR]\n",
            "                               [--run_further_training RUN_FURTHER_TRAINING] [--epochs EPOCHS]\n",
            "                               [--further_training_epochs FURTHER_TRAINING_EPOCHS] [--n_way N_WAY]\n",
            "                               [--k_spt K_SPT] [--k_qry K_QRY] [--imgsz IMGSZ] [--imgc IMGC]\n",
            "                               [--task_num TASK_NUM] [--meta_lr META_LR] [--update_lr UPDATE_LR]\n",
            "                               [--update_step UPDATE_STEP] [--update_step_test UPDATE_STEP_TEST]\n",
            "                               [--accuracy_log_file ACCURACY_LOG_FILE]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --train_dir TRAIN_DIR\n",
            "                        train data directory\n",
            "  --further_training_dir FURTHER_TRAINING_DIR\n",
            "                        further training data directory\n",
            "  --validation_dir VALIDATION_DIR\n",
            "                        validation data directory\n",
            "  --test_dir TEST_DIR   test data directory\n",
            "  --run_further_training RUN_FURTHER_TRAINING\n",
            "                        Boolean for adding a second dataset for further training. Set as string.\n",
            "                        Case insensitive.\n",
            "  --epochs EPOCHS       Number of epochs\n",
            "  --further_training_epochs FURTHER_TRAINING_EPOCHS\n",
            "                        Number of epochs for further training cycle\n",
            "  --n_way N_WAY         n way\n",
            "  --k_spt K_SPT         k shot for support set\n",
            "  --k_qry K_QRY         k shot for query set\n",
            "  --imgsz IMGSZ         imgsz\n",
            "  --imgc IMGC           imgc\n",
            "  --task_num TASK_NUM   meta batch size, namely task num\n",
            "  --meta_lr META_LR     meta-level outer learning rate\n",
            "  --update_lr UPDATE_LR\n",
            "                        task-level inner update learning rate\n",
            "  --update_step UPDATE_STEP\n",
            "                        task-level inner update steps\n",
            "  --update_step_test UPDATE_STEP_TEST\n",
            "                        update steps for fine-tuning\n",
            "  --accuracy_log_file ACCURACY_LOG_FILE\n",
            "                        Output file for mean test accuracy\n"
          ]
        }
      ],
      "source": [
        "!python /content/maml_pytorch/train_custom_dataset.py --help\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjY6ePw7wxfP",
        "outputId": "5c0f8613-ea13-4d5b-8e70-2a80af0793d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(train_dir='/content/miniimagenet/images', further_training_dir='/content/all_further_training_images', validation_dir='/content/all_validation_images', test_dir='/content/all_test_images', run_further_training=False, epochs=4000000, further_training_epochs=2000000, n_way=2, k_spt=1, k_qry=5, imgsz=84, imgc=3, task_num=4, meta_lr=0.001, update_lr=0.01, update_step=5, update_step_test=10, accuracy_log_file='/content/mean_test_accuracy.txt')\n",
            "Meta(\n",
            "  (net): Learner(\n",
            "    conv2d:(ch_in:3, ch_out:32, k:3x3, stride:1, padding:0)\n",
            "    relu:(True,)\n",
            "    bn:(32,)\n",
            "    max_pool2d:(k:2, stride:2, padding:0)\n",
            "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
            "    relu:(True,)\n",
            "    bn:(32,)\n",
            "    max_pool2d:(k:2, stride:2, padding:0)\n",
            "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
            "    relu:(True,)\n",
            "    bn:(32,)\n",
            "    max_pool2d:(k:2, stride:2, padding:0)\n",
            "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
            "    relu:(True,)\n",
            "    bn:(32,)\n",
            "    max_pool2d:(k:2, stride:1, padding:0)\n",
            "    flatten:()\n",
            "    linear:(in:800, out:2)\n",
            "    \n",
            "    (vars): ParameterList(\n",
            "        (0): Parameter containing: [torch.float32 of size 32x3x3x3 (cuda:0)]\n",
            "        (1): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (2): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (3): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (4): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
            "        (5): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (6): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (7): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (8): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
            "        (9): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (10): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (11): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (12): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
            "        (13): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (14): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (15): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (16): Parameter containing: [torch.float32 of size 2x800 (cuda:0)]\n",
            "        (17): Parameter containing: [torch.float32 of size 2 (cuda:0)]\n",
            "    )\n",
            "    (vars_bn): ParameterList(\n",
            "        (0): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (1): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (2): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (3): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (4): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (5): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (6): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "        (7): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total trainable tensors: 30498\n",
            "shuffle DB :train, b:50, 2-way, 1-shot, 5-query, resize:84\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'filename'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/maml_pytorch/train_custom_dataset.py\", line 231, in <module>\n",
            "    main()\n",
            "  File \"/content/maml_pytorch/train_custom_dataset.py\", line 66, in main\n",
            "    mini = MiniImagenet(train_image_directory, mode='train', n_way=args.n_way, k_shot=args.k_spt,\n",
            "  File \"/content/maml_pytorch/MiniImagenet.py\", line 65, in __init__\n",
            "    csvdata = self.loadCSV(os.path.join(root, mode + '.csv'))  # csv path\n",
            "  File \"/content/maml_pytorch/MiniImagenet.py\", line 89, in loadCSV\n",
            "    filename = row['filename']\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\", line 1121, in __getitem__\n",
            "    return self._get_value(key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\", line 1237, in _get_value\n",
            "    loc = self.index.get_loc(label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'filename'\n",
            "MAML execution time: 0.0019294084269444688 hrs\n"
          ]
        }
      ],
      "source": [
        "# run the training file\n",
        "\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "\n",
        "n_epochs = 400 * 10000 # must be a multiple of 10000\n",
        "\n",
        "train_dir = '/content/miniimagenet/images'\n",
        "!python /content/maml_pytorch/train_custom_dataset.py  --epochs {n_epochs} --run_further_training 'false'\n",
        "\n",
        "\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('MAML execution time: {} hrs'.format((stop - start)/60/60) )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4yuJ0RCUqkk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTnveARvCEoz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "\n",
        "print('Mean Validation Accuracy over Epochs')\n",
        "\n",
        "text_file = open('/content/mean_test_accuracy.txt', \"r\")\n",
        "mean_accs = text_file.read().split('\\n')\n",
        "mean_accs = [(float(ma) * 100) for ma in mean_accs]\n",
        "\n",
        "axes = plt.gca()\n",
        "axes.set_ylim([np.int(min(mean_accs)-2), np.int(max(mean_accs)) +2])\n",
        "\n",
        "plt.plot(mean_accs)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Accuracy')\n",
        "plt.title('Mean Validation Accuracy over Epochs')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8CNM0cudewf"
      },
      "outputs": [],
      "source": [
        "metrics = pd.read_csv('mean_metrics.csv')\n",
        "metrics.head()\n",
        "\n",
        "\n",
        "metrics[['train_loss', 'val_loss']].plot(figsize=(10,5), title='Train and Validation Loss over Epochs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8yA0OmweYW2"
      },
      "outputs": [],
      "source": [
        "metrics[['train_accuracy', 'val_accuracy']].plot(figsize=(10,5), title='Train and Validation Accuracy over Epochs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnJ94L5X3rCu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us5RosXM44wR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "# modified from main.py https://github.com/zhangrong1722/CheXNet-Pytorch\n",
        "\n",
        "def plt_roc(test_y, probas_y, plot_micro=False, plot_macro=False):\n",
        "    assert isinstance(test_y, list) and isinstance(probas_y, list), 'the type of input must be list'\n",
        "    skplt.metrics.plot_roc(test_y, probas_y, plot_micro=plot_micro, plot_macro=plot_macro)\n",
        "    plt.savefig('roc_auc_curve.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "###########################################\n",
        "# Define confusion matrix and ROC visualization functions\n",
        "# from https://colab.research.google.com/drive/1ISfhxFDntfOos7cOeT7swduSqzLEqyFn#scrollTo=UiKRYOWPfhJs\n",
        "\n",
        "def plot_confusion_matrix(cm, classes=None,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues,\n",
        "                          cv=10):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"\\nNormalized confusion matrix\")\n",
        "    else:\n",
        "        print('\\nConfusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    if classes:\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes, rotation=45)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 1.5\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.locator_params(nbins=2)\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPCU0a2g3OhG"
      },
      "outputs": [],
      "source": [
        "pred_df = pd.read_csv('test_predictions_and_labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTReVLrh4Th_"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Get the predicted labels for metric calculations.\n",
        "#\n",
        "# Since prototypical networks always sets the ground truth to 0,\n",
        "# infer the predicted class label from true label and the Boolean value for 'correct'\n",
        "# To do this, set hc to be -1 and sz to 1. This allows the opposite class to be selected\n",
        "# for rows where correct is False by multiplying the true_label by -1\n",
        "pred_df['true_label'] = pred_df.apply(lambda x: -1 if x['true_label'] == 0 else 1, axis=1)\n",
        "pred_df['correct'] = pred_df.apply(lambda x: 1 if x['correct'] == True else 0, axis=1)\n",
        "pred_df['prediction'] = pred_df.apply(lambda x: x['true_label']\n",
        "  if x['correct'] == 1 else x['true_label'] * -1, axis=1)\n",
        "pred_df.replace(-1, 0, inplace=True)\n",
        "# display(pred_df.head())\n",
        "# pred_df.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn3KjBgT4baC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "pred_y = pred_df['prediction'].values\n",
        "truth_y = pred_df['true_label'].values\n",
        "#probas_y = [s.replace('[', '').replace(']', '').split(', ') for s in best_model_preds['probas_y'].values]\n",
        "#probas_y = [[float(t[0]), float(t[1])] for t in probas_y]\n",
        "\n",
        "\n",
        "confusion = confusion_matrix(pred_y, truth_y)\n",
        "plot_confusion_matrix(confusion,\n",
        "                      classes=['hc', 'sz'],\n",
        "                      title='Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTBiitsce0fn"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('metrics_summary.csv')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}